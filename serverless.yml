useDotenv: true

service: poprox-default-recommender

provider:
  name: aws
  runtime: python3.11
  profile: admin
  # Enable versioning so provisioned concurrency can attach to an alias/version
  versionFunctions: true
  region: ${opt:region, "us-east-1"}
  stage: ${opt:stage, "local"}
  memorySize: 2048 # 2gb
  timeout: 30
  architecture: x86_64
  environment:
    OPENAI_API_KEY: ${env:OPENAI_API_KEY}
    PERSISTENCE_BUCKET: ${self:custom.pipelineBucket}
    PERSISTENCE_PREFIX: pipeline-outputs/
    # Keep Hugging Face/Transformers strictly offline at runtime to avoid
    # network fetch attempts during cold start initialization.
    TRANSFORMERS_OFFLINE: "1"
    HF_HOME: /tmp/huggingface

  iam:
    role:
      # Add statements to the IAM role to give permissions to Lambda functions
      statements:
        - Effect: Allow
          Action:
            - "logs:*"
          Resource: "*"
        - Effect: Allow
          Action:
            - "s3:GetObject"
            - "s3:PutObject"
            - "s3:DeleteObject"
            - "s3:ListBucket"
          Resource:
            - "arn:aws:s3:::${self:custom.pipelineBucket}"
            - "arn:aws:s3:::${self:custom.pipelineBucket}/*"

  ecr:
    # Using the pre-built image from ECR instead of building locally
    images:
      poprox-recommender:
        uri: 787842565111.dkr.ecr.us-east-1.amazonaws.com/serverless-poprox-default-recommender-prod:latest

package:
  patterns:
    - "!venv/**"
    - "!models/**"
    - "!node_modules/**"
    - "!tests/**"
    - "**.py"
    - "**.html"

functions:
  generateRecommendations:
    image:
      name: poprox-recommender
    memorySize: 4096
    ephemeralStorageSize: 2048
    # Keep at least one initialized execution environment to avoid 30s API GW timeout
    # on cold starts while large models/pipelines load.
    provisionedConcurrency: 1
    events:
      - httpApi:
          path: /warmup
          method: get
      - httpApi:
          path: /
          method: post

custom:
  pipelineBucket: ${self:service}-pipeline-data-${self:provider.stage}

resources:
  Resources:
    PipelineDataBucket:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.pipelineBucket}
        VersioningConfiguration:
          Status: Enabled
        LifecycleConfiguration:
          Rules:
            - Id: DeleteOldPipelineData
              Status: Enabled
              ExpirationInDays: 90 # Keep pipeline data for 90 days
              NoncurrentVersionExpirationInDays: 30
        PublicAccessBlockConfiguration:
          BlockPublicAcls: true
          BlockPublicPolicy: true
          IgnorePublicAcls: true
          RestrictPublicBuckets: true

  Outputs:
    PipelineDataBucketName:
      Description: "S3 bucket for storing pipeline data"
      Value: ${self:custom.pipelineBucket}
      Export:
        Name: ${self:service}-${self:provider.stage}-pipeline-bucket
